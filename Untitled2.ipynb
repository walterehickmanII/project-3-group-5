{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 79,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wbH8FQp9uB3n",
        "outputId": "cd367108-ae9f-4c3b-da90-d23e39fcc975"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!pip install nltk\n",
        "!pip install gdown\n",
        "!pip install openai"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "\n",
        "# Load the dataset\n",
        "file_path = \"/content/drive/MyDrive/Project3database.csv\"\n",
        "data = pd.read_csv(file_path)\n",
        "\n",
        "# Ensure 'Year' and 'Tm' columns are present\n",
        "if 'Year' not in data.columns or 'Tm' not in data.columns:\n",
        "    raise ValueError(\"'Year' and 'Tm' columns are required in the dataset.\")\n",
        "\n",
        "# Select relevant features for prediction\n",
        "features = ['R/G', 'G', 'PA', 'AB', 'RS', 'H', '2B', '3B', 'HR', 'RBI', 'SB', 'CS', 'BB', 'SO', 'BA', 'OBP', 'SLG', 'OPS']\n",
        "\n",
        "# Ensure there are no missing values in the features\n",
        "data_filtered = data.dropna(subset=features)\n",
        "\n",
        "# Generate random binary target data for demonstration purposes (since the real target data is cleared)\n",
        "data_filtered['Playoff'] = np.random.randint(2, size=len(data_filtered))\n",
        "data_filtered['Champion'] = np.random.randint(2, size=len(data_filtered))\n",
        "\n",
        "# Define the feature set and target variables\n",
        "X = data_filtered[features]\n",
        "y_playoff = data_filtered['Playoff']\n",
        "y_champion = data_filtered['Champion']\n",
        "\n",
        "# Standardize the features\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X)\n",
        "\n",
        "# Split the data into training and testing sets for playoff prediction\n",
        "X_train, X_test, y_playoff_train, y_playoff_test = train_test_split(X_scaled, y_playoff, test_size=0.2, random_state=42)\n",
        "\n",
        "# Train a RandomForestClassifier model for playoff prediction\n",
        "model_playoff = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "model_playoff.fit(X_train, y_playoff_train)\n",
        "\n",
        "# Make predictions on the test set for playoff prediction\n",
        "y_playoff_pred = model_playoff.predict(X_test)\n",
        "playoff_accuracy = accuracy_score(y_playoff_test, y_playoff_pred)\n",
        "print(\"Playoff Prediction Accuracy:\", playoff_accuracy)\n",
        "\n",
        "# Evaluate the playoff model\n",
        "print(\"Random Forest Classifier Evaluation for Playoff Prediction\")\n",
        "print(classification_report(y_playoff_test, y_playoff_pred))\n",
        "print(confusion_matrix(y_playoff_test, y_playoff_pred))\n",
        "\n",
        "# Split the data into training and testing sets for champion prediction\n",
        "_, _, y_champion_train, y_champion_test = train_test_split(X_scaled, y_champion, test_size=0.2, random_state=42)\n",
        "\n",
        "# Train a RandomForestClassifier model for champion prediction\n",
        "model_champion = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "model_champion.fit(X_train, y_champion_train)\n",
        "\n",
        "# Make predictions on the test set for champion prediction\n",
        "y_champion_pred = model_champion.predict(X_test)\n",
        "champion_accuracy = accuracy_score(y_champion_test, y_champion_pred)\n",
        "print(\"Champion Prediction Accuracy:\", champion_accuracy)\n",
        "\n",
        "# Evaluate the champion model\n",
        "print(\"Random Forest Classifier Evaluation for Champion Prediction\")\n",
        "print(classification_report(y_champion_test, y_champion_pred))\n",
        "print(confusion_matrix(y_champion_test, y_champion_pred))\n",
        "\n",
        "# Neural network model for playoff prediction\n",
        "model_playoff_nn = Sequential([\n",
        "    Dense(64, activation='relu', input_shape=(X_scaled.shape[1],)),\n",
        "    Dense(32, activation='relu'),\n",
        "    Dense(1, activation='sigmoid')\n",
        "])\n",
        "\n",
        "model_playoff_nn.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "model_playoff_nn.fit(X_train, y_playoff_train, epochs=50, batch_size=32, validation_split=0.2)\n",
        "\n",
        "# Evaluate the neural network model for playoff prediction\n",
        "playoff_nn_accuracy = model_playoff_nn.evaluate(X_test, y_playoff_test)\n",
        "print(\"Playoff Neural Network Prediction Accuracy:\", playoff_nn_accuracy[1])\n",
        "\n",
        "# Neural network model for champion prediction\n",
        "model_champion_nn = Sequential([\n",
        "    Dense(64, activation='relu', input_shape=(X_scaled.shape[1],)),\n",
        "    Dense(32, activation='relu'),\n",
        "    Dense(1, activation='sigmoid')\n",
        "])\n",
        "\n",
        "model_champion_nn.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "model_champion_nn.fit(X_train, y_champion_train, epochs=50, batch_size=32, validation_split=0.2)\n",
        "\n",
        "# Evaluate the neural network model for champion prediction\n",
        "champion_nn_accuracy = model_champion_nn.evaluate(X_test, y_champion_test)\n",
        "print(\"Champion Neural Network Prediction Accuracy:\", champion_nn_accuracy[1])\n",
        "\n",
        "# Function to predict playoff teams and champion for a given year\n",
        "def predict_for_year(year):\n",
        "    if year not in data['Year'].values:\n",
        "        print(f\"The year {year} is not in the dataset.\")\n",
        "        return\n",
        "\n",
        "    filtered_data = data[data['Year'] == year].copy()\n",
        "\n",
        "    # Ensure the same columns, in the same order, are used when transforming `future_data`\n",
        "    relevant_columns = X.columns\n",
        "    future_data = filtered_data[relevant_columns]\n",
        "\n",
        "    # Standardize the features\n",
        "    future_data_scaled = scaler.transform(future_data)\n",
        "\n",
        "    # Get the required number of playoff teams based on the year\n",
        "    if 2000 <= year <= 2011:\n",
        "        n_playoff_teams = 8\n",
        "    elif 2012 <= year <= 2019:\n",
        "        n_playoff_teams = 10\n",
        "    elif year == 2020:\n",
        "        n_playoff_teams = 16\n",
        "    elif 2022 <= year <= 2024:\n",
        "        n_playoff_teams = 12\n",
        "    else:\n",
        "        raise ValueError(\"Year is out of the expected range for this analysis\")\n",
        "\n",
        "    # Predict playoff teams\n",
        "    future_playoff_predictions_proba = model_playoff.predict_proba(future_data_scaled)[:, 1]\n",
        "    filtered_data['Playoff_Prob'] = future_playoff_predictions_proba\n",
        "\n",
        "    # Select top N teams based on playoff probability\n",
        "    playoff_teams = filtered_data.nlargest(n_playoff_teams, 'Playoff_Prob')\n",
        "    print(\"Teams predicted to be in playoffs:\")\n",
        "    print(playoff_teams[['Tm', 'Playoff_Prob']])\n",
        "\n",
        "    # Predict champions among the playoff teams\n",
        "    future_playoff_data = playoff_teams[relevant_columns]\n",
        "    future_playoff_data_scaled = scaler.transform(future_playoff_data)\n",
        "\n",
        "    future_champion_predictions_proba = model_champion.predict_proba(future_playoff_data_scaled)[:, 1]\n",
        "    playoff_teams['Champion_Prob'] = future_champion_predictions_proba\n",
        "\n",
        "    # Select the champion (team with the highest probability) among playoff teams\n",
        "    champion_team = playoff_teams.loc[playoff_teams['Champion_Prob'].idxmax()]\n",
        "    print(\"Team predicted to be the champion:\")\n",
        "    print(champion_team[['Tm', 'Champion_Prob']])\n",
        "\n",
        "# Ask the user for a year and make predictions\n",
        "try:\n",
        "    year_to_predict = int(input(\"Enter a year to predict playoffs and champion: \"))\n",
        "    predict_for_year(year_to_predict)\n",
        "except ValueError:\n",
        "    print(\"Please enter a valid year.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import gdown\n",
        "import os\n",
        "import openai\n",
        "from nltk.sentiment import SentimentIntensityAnalyzer\n",
        "import nltk\n",
        "\n",
        "# Download VADER lexicon (only need to do this once)\n",
        "nltk.download('vader_lexicon')\n",
        "\n",
        "# Initialize the sentiment analyzer\n",
        "sia = SentimentIntensityAnalyzer()\n",
        "\n",
        "# Google Drive file ID (part of the shareable link)\n",
        "file_id = '1p_ab8FVdg2ljxhrudkPNTETyoRLj6Ab9'\n",
        "output = 'env.text'\n",
        "\n",
        "# Construct the download URL\n",
        "url = f\"https://drive.google.com/uc?id={file_id}\"\n",
        "\n",
        "# Download the file from Google Drive\n",
        "gdown.download(url, output, quiet=False)\n",
        "\n",
        "# Read the API key from the file\n",
        "with open('env.text', 'r') as file:\n",
        "    api_key = file.read().strip()\n",
        "\n",
        "# Set the OpenAI API key\n",
        "os.environ['OPENAI_API_KEY'] = api_key\n",
        "openai.api_key = os.getenv('OPENAI_API_KEY')\n",
        "\n",
        "print(\"API Key successfully set!\")\n",
        "\n",
        "# Function to analyze sentiment\n",
        "def analyze_sentiment(text):\n",
        "    sentiment_scores = sia.polarity_scores(text)\n",
        "    return sentiment_scores\n",
        "\n",
        "# Function to predict playoff teams and champion for a given year\n",
        "def predict_for_year(year):\n",
        "    if year not in data['Year'].values:\n",
        "        print(f\"The year {year} is not in the dataset.\")\n",
        "        return\n",
        "\n",
        "    filtered_data = data[data['Year'] == year].copy()  # Use .copy() to avoid the SettingWithCopyWarning\n",
        "\n",
        "    # Ensure the same columns, in the same order, are used when transforming `future_data`\n",
        "    relevant_columns = X.columns\n",
        "    future_data = filtered_data[relevant_columns]\n",
        "\n",
        "    # Standardize the features\n",
        "    future_data_scaled = scaler.transform(future_data)\n",
        "\n",
        "    # Get the required number of playoff teams based on the year\n",
        "    if 2000 <= year <= 2011:\n",
        "        n_playoff_teams = 8\n",
        "    elif 2012 <= year <= 2019:\n",
        "        n_playoff_teams = 10\n",
        "    elif year == 2020:\n",
        "        n_playoff_teams = 16\n",
        "    elif 2022 <= year <= 2024:\n",
        "        n_playoff_teams = 12\n",
        "    else:\n",
        "        raise ValueError(\"Year is out of the expected range for this analysis\")\n",
        "\n",
        "    # Predict playoff teams\n",
        "    future_playoff_predictions_proba = model_playoff.predict_proba(future_data_scaled)[:, 1]\n",
        "    filtered_data['Playoff_Prob'] = future_playoff_predictions_proba\n",
        "\n",
        "    # Select top N teams based on playoff probability\n",
        "    playoff_teams = filtered_data.nlargest(n_playoff_teams, 'Playoff_Prob')\n",
        "    print(\"Teams predicted to be in playoffs:\")\n",
        "    print(playoff_teams[['Tm', 'Playoff_Prob']])\n",
        "\n",
        "    # Predict champions among playoff teams\n",
        "    playoff_teams_scaled = scaler.transform(playoff_teams[relevant_columns])\n",
        "    future_champion_predictions_proba = model_champion.predict_proba(playoff_teams_scaled)[:, 1]\n",
        "    playoff_teams['Champion_Prob'] = future_champion_predictions_proba\n",
        "\n",
        "    # Select the champion (team with the highest probability)\n",
        "    champion_team = playoff_teams.loc[playoff_teams['Champion_Prob'].idxmax()]\n",
        "    print(\"Team predicted to be the champion:\")\n",
        "    print(champion_team[['Tm', 'Champion_Prob']])\n",
        "\n",
        "    # Analyze sentiment based on the team name or any other relevant text\n",
        "    sentiment = analyze_sentiment(champion_team['Tm'])\n",
        "    print(f\"Sentiment for {champion_team['Tm']}: {sentiment}\")\n",
        "\n",
        "# Ask the user for a year and make predictions\n",
        "try:\n",
        "    year_to_predict = int(input(\"Enter a year to predict playoffs and champion: \"))\n",
        "    predict_for_year(year_to_predict)\n",
        "except ValueError:\n",
        "    print(\"Please enter a valid year.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "\n",
        "def load_and_preprocess_data(file_path):\n",
        "    \"\"\"Load and preprocess the dataset.\"\"\"\n",
        "    data = pd.read_csv(file_path)\n",
        "    \n",
        "    if 'Year' not in data.columns or 'Tm' not in data.columns:\n",
        "        raise ValueError(\"'Year' and 'Tm' columns are required in the dataset.\")\n",
        "    \n",
        "    features = ['R/G', 'G', 'PA', 'AB', 'RS', 'H', '2B', '3B', 'HR', 'RBI', 'SB', 'CS', 'BB', 'SO', 'BA', 'OBP', 'SLG', 'OPS']\n",
        "    \n",
        "    data_filtered = data.dropna(subset=features)\n",
        "    \n",
        "    # Generate random binary target data for demonstration purposes\n",
        "    np.random.seed(42)\n",
        "    data_filtered['Playoff'] = np.random.randint(2, size=len(data_filtered))\n",
        "    data_filtered['Champion'] = np.random.randint(2, size=len(data_filtered))\n",
        "    \n",
        "    X = data_filtered[features]\n",
        "    y_playoff = data_filtered['Playoff']\n",
        "    y_champion = data_filtered['Champion']\n",
        "    \n",
        "    scaler = StandardScaler()\n",
        "    X_scaled = scaler.fit_transform(X)\n",
        "    \n",
        "    return data, X_scaled, y_playoff, y_champion, scaler\n",
        "\n",
        "def train_random_forest(X_train, y_train):\n",
        "    \"\"\"Train a Random Forest classifier.\"\"\"\n",
        "    model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "    model.fit(X_train, y_train)\n",
        "    return model\n",
        "\n",
        "def evaluate_model(model, X_test, y_test, target_name=\"Prediction\"):\n",
        "    \"\"\"Evaluate the model using accuracy, classification report, and confusion matrix.\"\"\"\n",
        "    y_pred = model.predict(X_test)\n",
        "    accuracy = accuracy_score(y_test, y_pred)\n",
        "    print(f\"{target_name} Accuracy:\", accuracy)\n",
        "    print(f\"Random Forest Classifier Evaluation for {target_name}\")\n",
        "    print(classification_report(y_test, y_pred))\n",
        "    print(confusion_matrix(y_test, y_pred))\n",
        "\n",
        "def train_neural_network(X_train, y_train, input_shape):\n",
        "    \"\"\"Train a Neural Network.\"\"\"\n",
        "    model = Sequential([\n",
        "        Dense(64, activation='relu', input_shape=(input_shape,)),\n",
        "        Dense(32, activation='relu'),\n",
        "        Dense(1, activation='sigmoid')\n",
        "    ])\n",
        "    \n",
        "    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "    model.fit(X_train, y_train, epochs=50, batch_size=32, validation_split=0.2)\n",
        "    \n",
        "    return model\n",
        "\n",
        "def evaluate_neural_network(model, X_test, y_test, target_name=\"Neural Network Prediction\"):\n",
        "    \"\"\"Evaluate the Neural Network model.\"\"\"\n",
        "    accuracy = model.evaluate(X_test, y_test)\n",
        "    print(f\"{target_name} Accuracy:\", accuracy[1])\n",
        "\n",
        "def predict_for_year(year, data, scaler, model_playoff, model_champion):\n",
        "    \"\"\"Predict playoff teams and champion for a given year.\"\"\"\n",
        "    if year not in data['Year'].values:\n",
        "        print(f\"The year {year} is not in the dataset.\")\n",
        "        return\n",
        "\n",
        "    filtered_data = data[data['Year'] == year].copy()\n",
        "    relevant_columns = data.columns.drop(['Year', 'Tm', 'Playoff', 'Champion'])\n",
        "    future_data = filtered_data[relevant_columns]\n",
        "    future_data_scaled = scaler.transform(future_data)\n",
        "    \n",
        "    n_playoff_teams = None\n",
        "    if 2000 <= year <= 2011:\n",
        "        n_playoff_teams = 8\n",
        "    elif 2012 <= year <= 2019:\n",
        "        n_playoff_teams = 10\n",
        "    elif year == 2020:\n",
        "        n_playoff_teams = 16\n",
        "    elif 2022 <= year <= 2024:\n",
        "        n_playoff_teams = 12\n",
        "    else:\n",
        "        raise ValueError(\"Year is out of the expected range for this analysis\")\n",
        "\n",
        "    future_playoff_predictions_proba = model_playoff.predict_proba(future_data_scaled)[:, 1]\n",
        "    filtered_data['Playoff_Prob'] = future_playoff_predictions_proba\n",
        "    playoff_teams = filtered_data.nlargest(n_playoff_teams, 'Playoff_Prob')\n",
        "    print(\"Teams predicted to be in playoffs:\")\n",
        "    print(playoff_teams[['Tm', 'Playoff_Prob']])\n",
        "    \n",
        "    future_playoff_data = playoff_teams[relevant_columns]\n",
        "    future_playoff_data_scaled = scaler.transform(future_playoff_data)\n",
        "    \n",
        "    future_champion_predictions_proba = model_champion.predict_proba(future_playoff_data_scaled)[:, 1]\n",
        "    playoff_teams['Champion_Prob'] = future_champion_predictions_proba\n",
        "    champion_team = playoff_teams.loc[playoff_teams['Champion_Prob'].idxmax()]\n",
        "    print(\"Team predicted to be the champion:\")\n",
        "    print(champion_team[['Tm', 'Champion_Prob']])\n",
        "\n",
        "# Main execution\n",
        "file_path = \"/content/drive/MyDrive/Project3database.csv\"\n",
        "data, X_scaled, y_playoff, y_champion, scaler = load_and_preprocess_data(file_path)\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_playoff_train, y_playoff_test = train_test_split(X_scaled, y_playoff, test_size=0.2, random_state=42)\n",
        "\n",
        "# Train and evaluate Random Forest models\n",
        "model_playoff = train_random_forest(X_train, y_playoff_train)\n",
        "evaluate_model(model_playoff, X_test, y_playoff_test, target_name=\"Playoff Prediction\")\n",
        "\n",
        "_, _, y_champion_train, y_champion_test = train_test_split(X_scaled, y_champion, test_size=0.2, random_state=42)\n",
        "model_champion = train_random_forest(X_train, y_champion_train)\n",
        "evaluate_model(model_champion, X_test, y_champion_test, target_name=\"Champion Prediction\")\n",
        "\n",
        "# Train and evaluate Neural Network models\n",
        "model_playoff_nn = train_neural_network(X_train, y_playoff_train, X_scaled.shape[1])\n",
        "evaluate_neural_network(model_playoff_nn, X_test, y_playoff_test, target_name=\"Playoff Neural Network Prediction\")\n",
        "\n",
        "model_champion_nn = train_neural_network(X_train, y_champion_train, X_scaled.shape[1])\n",
        "evaluate_neural_network(model_champion_nn, X_test, y_champion_test, target_name=\"Champion Neural Network Prediction\")\n",
        "\n",
        "# Predict for a given year\n",
        "try:\n",
        "    year_to_predict = int(input(\"Enter a year to predict playoffs and champion: \"))\n",
        "    print(f\"Attempting to predict for the year: {year_to_predict}\")\n",
        "    predict_for_year(year_to_predict, data, scaler, model_playoff, model_champion)\n",
        "except ValueError:\n",
        "    print(\"Please enter a valid year.\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
